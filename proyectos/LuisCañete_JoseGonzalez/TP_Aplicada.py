# -*- coding: utf-8 -*-
"""Copia de BorradorMatematicaAplicada.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VRG4A8vp2BqFdC8_77clIKZM7ce1Jcc_

# Instalacion de Dependencias
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install scipy
# %pip install -U scikit-fuzzy
# %pip install pandas
# %pip install gdrive

import pandas as pd
import json
import gzip
import numpy as np
import skfuzzy as fuzz

from google.colab import drive
drive.mount('/content/drive')

"""# Modulo de Lector de Dataset"""

# Función para cargar datos de un archivo JSON comprimido en gzip
def load_gzipped_json(path):
    with gzip.open(path, 'rb') as file:
        return pd.DataFrame([json.loads(line) for line in file])

# Modificado
review_path='/content/drive/MyDrive/TrabajoPractico-MatematicaAplicada/Gift_Cards.json.gz'
# modificado
product_path='/content/drive/MyDrive/TrabajoPractico-MatematicaAplicada/meta_Gift_Cards.json.gz'

"""DataSet de los reviews

"""

# modificado
df_reviews = load_gzipped_json(review_path)[['overall','asin']]
df_reviews

"""Data set de productos"""

# modificado

df_products = load_gzipped_json(product_path)[['title','also_buy','also_view','asin']]
df_products

"""#Modulo 2 - Similarity Score

El similarity score puede ser calculado por diferentes metodos, inicialmente el planteado fue el del coseno, pero se termino usando el de jacta

> Bloque con sangría

## 2.1 Calculo de RatingScore

## 2.2 Calculo de SimilarityScore

#Modulo 4: Sistema de inferencia difuso

Se utilizaron conjuntos triangulares que reflejan una mejor manera los parametros de rating score.

*   Para los conjuntos bajos se usa -1 para que el 0 tenga un grado de pertencenciad e 1.
*  Para los conujuntos altos se utilizo 2 para que el 1 teng un grado de pertenencia de 1 los mismo para los demas.

Reglas


1.   Regla 1

     Si ***similarity_score*** es bajo y ***rating_score*** es bajo, entonces ***recomendation_score*** es baja

2.   Regla 1

     Si ***similarity_score*** es bajo y ***rating_score*** es medio, entonces ***recomendation_score*** es baja

3.   Regla 1

     Si ***similarity_score*** es bajo y ***rating_score*** es alto, entonces ***recomendation_score*** es media
4.   Regla 1

     Si ***similarity_score*** es medio y ***rating_score*** es bajo, entonces ***recomendation_score*** es baja
5.   Regla 1

     Si ***similarity_score*** es medio y ***rating_score*** es medio, entonces ***recomendation_score*** es baja

6.   Regla 1

     Si ***similarity_score*** es medio y ***rating_score*** es alto, entonces ***recomendation_score*** es alta

7.   Regla

     Si ***similarity_score*** es alto y ***rating_score*** es bajo, entonces ***recomendation_score*** es medio
  
8.   Regla

     Si ***similarity_score*** es alto y ***rating_score*** es medio, entonces ***recomendation_score*** es medio
9.   Regla

     Si ***similarity_score*** es alto y ***rating_score*** es alto, entonces ***recomendation_score*** es alta
"""

import pandas as pd
import numpy as np
import json
import gzip

# Función para calcular la calificación promedio de un producto específico en un DataFrame.
def calculate_rating_score(df, asin):
    # Devuelve la media de las calificaciones para el producto con el ASIN especificado.
    return df.loc[df['asin'] == asin, 'overall'].mean()

# Función para calcular la similaridad de Jaccard entre dos conjuntos.
def jaccard_similarity(set1, set2):
    # Calcula la intersección y unión de dos conjuntos y devuelve su cociente.
    intersection = set(set1).intersection(set(set2))
    union = set(set1).union(set(set2))
    return len(intersection) / len(union) if union else 0

# Función para calcular la similaridad de Jaccard entre dos productos usando sus datos de 'also_view' y 'also_buy'.
def calculate_jaccard_similarity(df_products, asinProductoA, asinProductoB):
    # Selecciona los datos relevantes de cada producto.
    df_productoA = df_products[df_products['asin'] == asinProductoA]
    df_productoB = df_products[df_products['asin'] == asinProductoB]

    # Obtiene las listas de productos también vistos y comprados para cada producto.
    A_also_view_set = df_productoA['also_view'].tolist()
    A_also_buy_set = df_productoA['also_buy'].tolist()
    B_also_view_set = df_productoB['also_view'].tolist()
    B_also_buy_set = df_productoB['also_buy'].tolist()

    # Si alguna de las listas está vacía, devuelve 0.
    if not A_also_view_set or not A_also_buy_set or not B_also_view_set or not B_also_buy_set:
        return 0

    # Calcula la similaridad de Jaccard para ambas listas y devuelve su promedio.
    jaccard_view = jaccard_similarity(A_also_view_set[0], B_also_view_set[0])
    jaccard_buy = jaccard_similarity(A_also_buy_set[0], B_also_buy_set[0])
    avg_jaccard = (jaccard_view + jaccard_buy) / 2
    return avg_jaccard

# Función para unificar las listas 'also_view' y 'also_buy' de un producto.
def MergeSets(df_products, asin_seleccionado):
    # Selecciona los datos del producto especificado.
    df_products_prod = df_products[df_products['asin'] == asin_seleccionado]

    # Si encuentra una fila correspondiente al producto, unifica las listas y devuelve la lista unificada.
    if len(df_products_prod) == 1:
        also_view = df_products_prod['also_view'].tolist()[0]
        also_buy = df_products_prod['also_buy'].tolist()[0]
        return list(set(also_view) | set(also_buy))

# Función para calcular la similaridad de Jaccard usando la función MergeSets.
def calculate_jaccard_similarity2(df_products, asinProductoA, asinProductoB):
    conjuntoA = MergeSets(df_products, asinProductoA)
    conjuntoB = MergeSets(df_products, asinProductoB)
    avg_jaccard = jaccard_similarity(conjuntoA, conjuntoB)
    return avg_jaccard

# Función de membresía difusa triangular.
def triangular_membership_degree(x, triangular_number):
    a, b, c = triangular_number
    return max(min((x-a)/(b-a), (c-x)/(c-b)), 0)

# Función de inferencia de Mamdani para la lógica difusa.
def mamdani_inference(similarity, rating, rules):
    index = 0
    index_max = 0
    maxDefuzedValue = 0
    for similarity_antecedent_set, rating_antecedent_set, recommendation_consecuent_set in rules:
        # Calcula la fuerza de activación para cada regla.
        sim_score = triangular_membership_degree(similarity, similarity_antecedent_set)
        rate_score = triangular_membership_degree(rating, rating_antecedent_set)
        rule_strength = min(sim_score, rate_score)

        # Recorta el conjunto difuso consecuente de acuerdo a la fuerza de activación.
        rec_set = [min(rule_strength, triangular_membership_degree(x/100, recommendation_consecuent_set)) for x in range(100)]

        # Calcula el valor desdifusificado para cada conjunto recortado.
        defuzedValue = defuzzify(rec_set)

        # Determina la regla con el valor desdifusificado máximo.
        if(defuzedValue > maxDefuzedValue):
            maxDefuzedValue = defuzedValue
            index_max = index
        index += 1

    # Devuelve el valor máximo desdifusificado y el índice de la regla correspondiente.
    return maxDefuzedValue, index_max

# Función de desdifusificación.
def defuzzify(aggregated_output):
    length = len(aggregated_output)
    x_values = np.linspace(0, 1, length)  # Genera valores x entre 0 y 1.
    numerator = np.sum(x_values * aggregated_output)
    denominator = np.sum(aggregated_output)

    # Evita la división por cero.
    if denominator == 0:
        return 0
    else:
        centroid = numerator / denominator
        return centroid

# Función para imprimir las recomendaciones.
def print_top(recommendations, df_products):
    # Ordena las recomendaciones de mayor a menor basado en el valor desdifusificado.
    top = sorted(recommendations, key=lambda x: x[2], reverse=True)[:10]
    for asin, recommendation, rule_index in top:
        # Imprime la recomendación junto con el índice de la regla aplicada.
        producto = df_products[df_products['asin'] == asin]
        print(f"Recomendación {asin}, regla {rule_index + 1}: {recommendation}")

# Aquí se cargarían los datos desde archivos JSON comprimidos en gzip.
# df_reviews = load_gzipped_json(review_path)[['overall','asin']]
# df_products = load_gzipped_json(product_path)[['title','also_buy','also_view','asin']]

# Definición de antecedentes y consecuentes como triángulos difusos para las reglas difusas.
rating_score_bajo = [-1,0,3]
rating_score_medio = [2,3,4]
rating_score_alto= [3,5,6]
similarity_score_bajo = [-1,0,0.4]
similarity_score_medio = [0.3,0.5,0.7]
similarity_score_alto= [0.6,1,2]
recomendacion_baja=[-1,0,0.4]
recomendacion_media=[0.3,0.5,0.7]
recomendacion_alta=[0.6,1,2]

rules = [
    # Definición de las reglas difusas.
    (similarity_score_bajo, rating_score_bajo, recomendacion_baja),   # Regla 1
    (similarity_score_bajo, rating_score_medio, recomendacion_baja),  # Regla 2
    (similarity_score_bajo, rating_score_alto, recomendacion_media),  # Regla 3
    (similarity_score_medio, rating_score_bajo, recomendacion_baja),  # Regla 4
    (similarity_score_medio, rating_score_medio, recomendacion_media),# Regla 5
    (similarity_score_medio, rating_score_alto, recomendacion_media), # Regla 6
    (similarity_score_alto, rating_score_bajo, recomendacion_alta),   # Regla 7
    (similarity_score_alto, rating_score_medio, recomendacion_alta),  # Regla 8
    (similarity_score_alto, rating_score_alto, recomendacion_alta),   # Regla 9
]

# Procesamiento de cada producto para obtener recomendaciones.
producto_A = 'B01GP1W4LA'  # Producto de referencia.
recommendations = []
for producto_B in df_products['asin']:
    if producto_B != producto_A:
        # Calcula la similaridad y la calificación del producto B en comparación con el producto A.
        similarity_score = calculate_jaccard_similarity2(df_products, producto_A, producto_B)
        rating_score = calculate_rating_score(df_reviews, producto_B)
        recomendation, rule_index = mamdani_inference(similarity_score, rating_score, rules)
        recommendations.append((producto_B, recomendation, rule_index))

# Imprime las recomendaciones.
print_top(recommendations, df_products)